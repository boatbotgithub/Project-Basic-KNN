{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "14_KNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0wwldfTxubo"
      },
      "source": [
        "## k-nearest neighbor classification  with iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APiNqoXgxubr"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "rQFkQKsNxubu",
        "outputId": "48c21dd2-133a-4235-a191-33354a833ec5"
      },
      "source": [
        "df=pd.read_csv('/content/wheat kernels.csv')\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>P</th>\n",
              "      <th>C</th>\n",
              "      <th>LK</th>\n",
              "      <th>WK</th>\n",
              "      <th>A_Coef</th>\n",
              "      <th>LKG</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14.59</td>\n",
              "      <td>14.28</td>\n",
              "      <td>0.8993</td>\n",
              "      <td>5.351</td>\n",
              "      <td>3.333</td>\n",
              "      <td>4.185</td>\n",
              "      <td>4.781</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>16.82</td>\n",
              "      <td>15.51</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>6.017</td>\n",
              "      <td>3.486</td>\n",
              "      <td>4.004</td>\n",
              "      <td>5.841</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>16.16</td>\n",
              "      <td>15.33</td>\n",
              "      <td>0.8644</td>\n",
              "      <td>5.845</td>\n",
              "      <td>3.395</td>\n",
              "      <td>4.266</td>\n",
              "      <td>5.795</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>17.36</td>\n",
              "      <td>15.76</td>\n",
              "      <td>0.8785</td>\n",
              "      <td>6.145</td>\n",
              "      <td>3.574</td>\n",
              "      <td>3.526</td>\n",
              "      <td>5.971</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>12.72</td>\n",
              "      <td>13.57</td>\n",
              "      <td>0.8686</td>\n",
              "      <td>5.226</td>\n",
              "      <td>3.049</td>\n",
              "      <td>4.102</td>\n",
              "      <td>4.914</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>15.05</td>\n",
              "      <td>14.68</td>\n",
              "      <td>0.8779</td>\n",
              "      <td>5.712</td>\n",
              "      <td>3.328</td>\n",
              "      <td>2.129</td>\n",
              "      <td>5.360</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>19.51</td>\n",
              "      <td>16.71</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>6.366</td>\n",
              "      <td>3.801</td>\n",
              "      <td>2.962</td>\n",
              "      <td>6.185</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>11.55</td>\n",
              "      <td>13.10</td>\n",
              "      <td>0.8455</td>\n",
              "      <td>5.167</td>\n",
              "      <td>2.845</td>\n",
              "      <td>6.715</td>\n",
              "      <td>4.956</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>15.38</td>\n",
              "      <td>14.66</td>\n",
              "      <td>0.8990</td>\n",
              "      <td>5.477</td>\n",
              "      <td>3.465</td>\n",
              "      <td>3.600</td>\n",
              "      <td>5.439</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>14.80</td>\n",
              "      <td>14.52</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>5.656</td>\n",
              "      <td>3.288</td>\n",
              "      <td>3.112</td>\n",
              "      <td>5.309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A      P       C     LK     WK  A_Coef    LKG  target\n",
              "15   14.59  14.28  0.8993  5.351  3.333   4.185  4.781       0\n",
              "74   16.82  15.51  0.8786  6.017  3.486   4.004  5.841       1\n",
              "133  16.16  15.33  0.8644  5.845  3.395   4.266  5.795       1\n",
              "136  17.36  15.76  0.8785  6.145  3.574   3.526  5.971       1\n",
              "19   12.72  13.57  0.8686  5.226  3.049   4.102  4.914       0\n",
              "34   15.05  14.68  0.8779  5.712  3.328   2.129  5.360       0\n",
              "84   19.51  16.71  0.8780  6.366  3.801   2.962  6.185       1\n",
              "171  11.55  13.10  0.8455  5.167  2.845   6.715  4.956       2\n",
              "135  15.38  14.66  0.8990  5.477  3.465   3.600  5.439       1\n",
              "38   14.80  14.52  0.8823  5.656  3.288   3.112  5.309       0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnwt8j6Uxubv",
        "outputId": "e1ede040-5033-41d7-b9b2-2acb3c1cad88"
      },
      "source": [
        "df.target.value_counts()\n",
        "#df.species.value_counts() # counting the lable class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    70\n",
              "1    70\n",
              "0    70\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhOZqgoQxubv",
        "outputId": "2cebce53-c0f6-4b8f-968a-dfba3ddde016"
      },
      "source": [
        "df.columns # feature all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A', 'P', 'C', 'LK', 'WK', 'A_Coef', 'LKG', 'target'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy0av_2Kxubw",
        "outputId": "f5110b23-577d-4e87-add8-cc8af2fef051"
      },
      "source": [
        "df.info() # target object label data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 210 entries, 0 to 209\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A       210 non-null    float64\n",
            " 1   P       210 non-null    float64\n",
            " 2   C       210 non-null    float64\n",
            " 3   LK      210 non-null    float64\n",
            " 4   WK      210 non-null    float64\n",
            " 5   A_Coef  210 non-null    float64\n",
            " 6   LKG     210 non-null    float64\n",
            " 7   target  210 non-null    int64  \n",
            "dtypes: float64(7), int64(1)\n",
            "memory usage: 13.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjqPsNNjxubw"
      },
      "source": [
        "# Scikit-learn: KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeYfUQEHxubw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjSMbzayxubx"
      },
      "source": [
        "cols=['A', 'P', 'C', 'LK', 'WK', 'A_Coef', 'LKG'] # featrue for classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KP-WwSnxubx"
      },
      "source": [
        "X=df[cols]\n",
        "y=df['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-EUmTqMdxuby"
      },
      "source": [
        "test_size=0.2  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTxE6DIAxuby"
      },
      "source": [
        "import numpy as np\n",
        "error_rate = []\n",
        "\n",
        "# Calculating error for K values between 1 and 10\n",
        "for i in range(1, 11):\n",
        "    model_knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    model_knn.fit(X_train, y_train)\n",
        "    pred_i =  model_knn.predict(X_train)\n",
        "    error_rate.append(np.mean(pred_i != y_train))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVmSlf7Exubz",
        "outputId": "a90f0837-efeb-4b7d-9e8f-ee0a1ed0c43a"
      },
      "source": [
        "error_rate # k=1 to k=10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.03571428571428571,\n",
              " 0.047619047619047616,\n",
              " 0.08928571428571429,\n",
              " 0.09523809523809523,\n",
              " 0.08928571428571429,\n",
              " 0.09523809523809523,\n",
              " 0.08333333333333333,\n",
              " 0.09523809523809523,\n",
              " 0.10714285714285714]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdd4HTFRxub0",
        "outputId": "7d9b9d40-75ac-4bb7-c7ce-ba76ac5f3d60"
      },
      "source": [
        "model = KNeighborsClassifier(n_neighbors=9) #n_neighbors=9 error_rate 0.0083\n",
        "model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SVirXztxub0",
        "outputId": "bcc56e61-1ada-4caa-baaa-ced4e7c658d6"
      },
      "source": [
        "model.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2VCCsSRL4uad",
        "outputId": "4f368465-52d1-4078-d4f0-c5418c58e829"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>P</th>\n",
              "      <th>C</th>\n",
              "      <th>LK</th>\n",
              "      <th>WK</th>\n",
              "      <th>A_Coef</th>\n",
              "      <th>LKG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>18.94</td>\n",
              "      <td>16.49</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>6.445</td>\n",
              "      <td>3.639</td>\n",
              "      <td>5.0640</td>\n",
              "      <td>6.362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>12.88</td>\n",
              "      <td>13.50</td>\n",
              "      <td>0.8879</td>\n",
              "      <td>5.139</td>\n",
              "      <td>3.119</td>\n",
              "      <td>2.3520</td>\n",
              "      <td>4.607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>18.36</td>\n",
              "      <td>16.52</td>\n",
              "      <td>0.8452</td>\n",
              "      <td>6.666</td>\n",
              "      <td>3.485</td>\n",
              "      <td>4.9330</td>\n",
              "      <td>6.448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>15.88</td>\n",
              "      <td>14.90</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>5.618</td>\n",
              "      <td>3.507</td>\n",
              "      <td>0.7651</td>\n",
              "      <td>5.091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>13.22</td>\n",
              "      <td>13.84</td>\n",
              "      <td>0.8680</td>\n",
              "      <td>5.395</td>\n",
              "      <td>3.070</td>\n",
              "      <td>4.1570</td>\n",
              "      <td>5.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>15.36</td>\n",
              "      <td>14.76</td>\n",
              "      <td>0.8861</td>\n",
              "      <td>5.701</td>\n",
              "      <td>3.393</td>\n",
              "      <td>1.3670</td>\n",
              "      <td>5.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>19.31</td>\n",
              "      <td>16.59</td>\n",
              "      <td>0.8815</td>\n",
              "      <td>6.341</td>\n",
              "      <td>3.810</td>\n",
              "      <td>3.4770</td>\n",
              "      <td>6.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>14.03</td>\n",
              "      <td>14.16</td>\n",
              "      <td>0.8796</td>\n",
              "      <td>5.438</td>\n",
              "      <td>3.201</td>\n",
              "      <td>1.7170</td>\n",
              "      <td>5.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.6990</td>\n",
              "      <td>4.825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>11.19</td>\n",
              "      <td>13.05</td>\n",
              "      <td>0.8253</td>\n",
              "      <td>5.250</td>\n",
              "      <td>2.675</td>\n",
              "      <td>5.8130</td>\n",
              "      <td>5.219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>15.01</td>\n",
              "      <td>14.76</td>\n",
              "      <td>0.8657</td>\n",
              "      <td>5.789</td>\n",
              "      <td>3.245</td>\n",
              "      <td>1.7910</td>\n",
              "      <td>5.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>17.99</td>\n",
              "      <td>15.86</td>\n",
              "      <td>0.8992</td>\n",
              "      <td>5.890</td>\n",
              "      <td>3.694</td>\n",
              "      <td>2.0680</td>\n",
              "      <td>5.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>16.87</td>\n",
              "      <td>15.65</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>6.139</td>\n",
              "      <td>3.463</td>\n",
              "      <td>3.6960</td>\n",
              "      <td>5.967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>16.82</td>\n",
              "      <td>15.51</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>6.017</td>\n",
              "      <td>3.486</td>\n",
              "      <td>4.0040</td>\n",
              "      <td>5.841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>20.97</td>\n",
              "      <td>17.25</td>\n",
              "      <td>0.8859</td>\n",
              "      <td>6.563</td>\n",
              "      <td>3.991</td>\n",
              "      <td>4.6770</td>\n",
              "      <td>6.316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>12.54</td>\n",
              "      <td>13.67</td>\n",
              "      <td>0.8425</td>\n",
              "      <td>5.451</td>\n",
              "      <td>2.879</td>\n",
              "      <td>3.0820</td>\n",
              "      <td>5.491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>18.72</td>\n",
              "      <td>16.34</td>\n",
              "      <td>0.8810</td>\n",
              "      <td>6.219</td>\n",
              "      <td>3.684</td>\n",
              "      <td>2.1880</td>\n",
              "      <td>6.097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>20.20</td>\n",
              "      <td>16.89</td>\n",
              "      <td>0.8894</td>\n",
              "      <td>6.285</td>\n",
              "      <td>3.864</td>\n",
              "      <td>5.1730</td>\n",
              "      <td>6.187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>19.51</td>\n",
              "      <td>16.71</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>6.366</td>\n",
              "      <td>3.801</td>\n",
              "      <td>2.9620</td>\n",
              "      <td>6.185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>19.94</td>\n",
              "      <td>16.92</td>\n",
              "      <td>0.8752</td>\n",
              "      <td>6.675</td>\n",
              "      <td>3.763</td>\n",
              "      <td>3.2520</td>\n",
              "      <td>6.550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>11.24</td>\n",
              "      <td>13.00</td>\n",
              "      <td>0.8359</td>\n",
              "      <td>5.090</td>\n",
              "      <td>2.715</td>\n",
              "      <td>3.5210</td>\n",
              "      <td>5.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>12.05</td>\n",
              "      <td>13.41</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>5.267</td>\n",
              "      <td>2.847</td>\n",
              "      <td>4.9880</td>\n",
              "      <td>5.046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>18.27</td>\n",
              "      <td>16.09</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>6.173</td>\n",
              "      <td>3.651</td>\n",
              "      <td>2.4430</td>\n",
              "      <td>6.197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>11.23</td>\n",
              "      <td>12.82</td>\n",
              "      <td>0.8594</td>\n",
              "      <td>5.089</td>\n",
              "      <td>2.821</td>\n",
              "      <td>7.5240</td>\n",
              "      <td>4.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>18.96</td>\n",
              "      <td>16.20</td>\n",
              "      <td>0.9077</td>\n",
              "      <td>6.051</td>\n",
              "      <td>3.897</td>\n",
              "      <td>4.3340</td>\n",
              "      <td>5.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>11.83</td>\n",
              "      <td>13.23</td>\n",
              "      <td>0.8496</td>\n",
              "      <td>5.263</td>\n",
              "      <td>2.840</td>\n",
              "      <td>5.1950</td>\n",
              "      <td>5.307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>10.82</td>\n",
              "      <td>12.83</td>\n",
              "      <td>0.8256</td>\n",
              "      <td>5.180</td>\n",
              "      <td>2.630</td>\n",
              "      <td>4.8530</td>\n",
              "      <td>5.089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>16.16</td>\n",
              "      <td>15.33</td>\n",
              "      <td>0.8644</td>\n",
              "      <td>5.845</td>\n",
              "      <td>3.395</td>\n",
              "      <td>4.2660</td>\n",
              "      <td>5.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>18.17</td>\n",
              "      <td>16.26</td>\n",
              "      <td>0.8637</td>\n",
              "      <td>6.271</td>\n",
              "      <td>3.512</td>\n",
              "      <td>2.8530</td>\n",
              "      <td>6.273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>11.35</td>\n",
              "      <td>13.12</td>\n",
              "      <td>0.8291</td>\n",
              "      <td>5.176</td>\n",
              "      <td>2.668</td>\n",
              "      <td>4.3370</td>\n",
              "      <td>5.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>13.20</td>\n",
              "      <td>13.66</td>\n",
              "      <td>0.8883</td>\n",
              "      <td>5.236</td>\n",
              "      <td>3.232</td>\n",
              "      <td>8.3150</td>\n",
              "      <td>5.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>12.37</td>\n",
              "      <td>13.47</td>\n",
              "      <td>0.8567</td>\n",
              "      <td>5.204</td>\n",
              "      <td>2.960</td>\n",
              "      <td>3.9190</td>\n",
              "      <td>5.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>11.42</td>\n",
              "      <td>12.86</td>\n",
              "      <td>0.8683</td>\n",
              "      <td>5.008</td>\n",
              "      <td>2.850</td>\n",
              "      <td>2.7000</td>\n",
              "      <td>4.607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>18.65</td>\n",
              "      <td>16.41</td>\n",
              "      <td>0.8698</td>\n",
              "      <td>6.285</td>\n",
              "      <td>3.594</td>\n",
              "      <td>4.3910</td>\n",
              "      <td>6.102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>16.53</td>\n",
              "      <td>15.34</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>5.875</td>\n",
              "      <td>3.467</td>\n",
              "      <td>5.5320</td>\n",
              "      <td>5.880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>11.02</td>\n",
              "      <td>13.00</td>\n",
              "      <td>0.8189</td>\n",
              "      <td>5.325</td>\n",
              "      <td>2.701</td>\n",
              "      <td>6.7350</td>\n",
              "      <td>5.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>19.15</td>\n",
              "      <td>16.45</td>\n",
              "      <td>0.8890</td>\n",
              "      <td>6.245</td>\n",
              "      <td>3.815</td>\n",
              "      <td>3.0840</td>\n",
              "      <td>6.185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>14.92</td>\n",
              "      <td>14.43</td>\n",
              "      <td>0.9006</td>\n",
              "      <td>5.384</td>\n",
              "      <td>3.412</td>\n",
              "      <td>1.1420</td>\n",
              "      <td>5.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>19.06</td>\n",
              "      <td>16.45</td>\n",
              "      <td>0.8854</td>\n",
              "      <td>6.416</td>\n",
              "      <td>3.719</td>\n",
              "      <td>2.2480</td>\n",
              "      <td>6.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>16.44</td>\n",
              "      <td>15.25</td>\n",
              "      <td>0.8880</td>\n",
              "      <td>5.884</td>\n",
              "      <td>3.505</td>\n",
              "      <td>1.9690</td>\n",
              "      <td>5.533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>12.80</td>\n",
              "      <td>13.47</td>\n",
              "      <td>0.8860</td>\n",
              "      <td>5.160</td>\n",
              "      <td>3.126</td>\n",
              "      <td>4.8730</td>\n",
              "      <td>4.914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>18.85</td>\n",
              "      <td>16.17</td>\n",
              "      <td>0.9056</td>\n",
              "      <td>6.152</td>\n",
              "      <td>3.806</td>\n",
              "      <td>2.8430</td>\n",
              "      <td>6.200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A      P       C     LK     WK  A_Coef    LKG\n",
              "78   18.94  16.49  0.8750  6.445  3.639  5.0640  6.362\n",
              "65   12.88  13.50  0.8879  5.139  3.119  2.3520  4.607\n",
              "94   18.36  16.52  0.8452  6.666  3.485  4.9330  6.448\n",
              "22   15.88  14.90  0.8988  5.618  3.507  0.7651  5.091\n",
              "63   13.22  13.84  0.8680  5.395  3.070  4.1570  5.088\n",
              "46   15.36  14.76  0.8861  5.701  3.393  1.3670  5.132\n",
              "96   19.31  16.59  0.8815  6.341  3.810  3.4770  6.238\n",
              "11   14.03  14.16  0.8796  5.438  3.201  1.7170  5.001\n",
              "2    14.29  14.09  0.9050  5.291  3.337  2.6990  4.825\n",
              "155  11.19  13.05  0.8253  5.250  2.675  5.8130  5.219\n",
              "24   15.01  14.76  0.8657  5.789  3.245  1.7910  5.001\n",
              "101  17.99  15.86  0.8992  5.890  3.694  2.0680  5.837\n",
              "95   16.87  15.65  0.8648  6.139  3.463  3.6960  5.967\n",
              "74   16.82  15.51  0.8786  6.017  3.486  4.0040  5.841\n",
              "114  20.97  17.25  0.8859  6.563  3.991  4.6770  6.316\n",
              "160  12.54  13.67  0.8425  5.451  2.879  3.0820  5.491\n",
              "99   18.72  16.34  0.8810  6.219  3.684  2.1880  6.097\n",
              "82   20.20  16.89  0.8894  6.285  3.864  5.1730  6.187\n",
              "84   19.51  16.71  0.8780  6.366  3.801  2.9620  6.185\n",
              "108  19.94  16.92  0.8752  6.675  3.763  3.2520  6.550\n",
              "169  11.24  13.00  0.8359  5.090  2.715  3.5210  5.088\n",
              "162  12.05  13.41  0.8416  5.267  2.847  4.9880  5.046\n",
              "85   18.27  16.09  0.8870  6.173  3.651  2.4430  6.197\n",
              "188  11.23  12.82  0.8594  5.089  2.821  7.5240  4.957\n",
              "116  18.96  16.20  0.9077  6.051  3.897  4.3340  5.750\n",
              "150  11.83  13.23  0.8496  5.263  2.840  5.1950  5.307\n",
              "193  10.82  12.83  0.8256  5.180  2.630  4.8530  5.089\n",
              "133  16.16  15.33  0.8644  5.845  3.395  4.2660  5.795\n",
              "98   18.17  16.26  0.8637  6.271  3.512  2.8530  6.273\n",
              "168  11.35  13.12  0.8291  5.176  2.668  4.3370  5.132\n",
              "207  13.20  13.66  0.8883  5.236  3.232  8.3150  5.056\n",
              "204  12.37  13.47  0.8567  5.204  2.960  3.9190  5.001\n",
              "60   11.42  12.86  0.8683  5.008  2.850  2.7000  4.607\n",
              "126  18.65  16.41  0.8698  6.285  3.594  4.3910  6.102\n",
              "80   16.53  15.34  0.8823  5.875  3.467  5.5320  5.880\n",
              "170  11.02  13.00  0.8189  5.325  2.701  6.7350  5.163\n",
              "117  19.15  16.45  0.8890  6.245  3.815  3.0840  6.185\n",
              "57   14.92  14.43  0.9006  5.384  3.412  1.1420  5.088\n",
              "115  19.06  16.45  0.8854  6.416  3.719  2.2480  6.163\n",
              "9    16.44  15.25  0.8880  5.884  3.505  1.9690  5.533\n",
              "195  12.80  13.47  0.8860  5.160  3.126  4.8730  4.914\n",
              "106  18.85  16.17  0.9056  6.152  3.806  2.8430  6.200"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuMN7NT648Lk",
        "outputId": "9ffad021-42b4-46e0-ada4-fccba44eae05"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpiH5yRxub0",
        "outputId": "83e30fad-5b68-4bd3-c8e9-50c4fd760da1"
      },
      "source": [
        "predicted = model.predict(X_test) \n",
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2,\n",
              "       1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8wMDsMG76P-"
      },
      "source": [
        "# ทดสอบหาคำตอบ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "j64XXj8J5taj",
        "outputId": "bfe409b7-29f2-40ea-b2ca-828b6e57d53d"
      },
      "source": [
        "tt = np.array([[11.49,13.22,0.8263,5.304,2.695,5.388,5.31]])\n",
        "df2 = pd.DataFrame(tt, columns = ['A', 'P', 'C', 'LK', 'WK', 'A_Coef', 'LKG'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>P</th>\n",
              "      <th>C</th>\n",
              "      <th>LK</th>\n",
              "      <th>WK</th>\n",
              "      <th>A_Coef</th>\n",
              "      <th>LKG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.49</td>\n",
              "      <td>13.22</td>\n",
              "      <td>0.8263</td>\n",
              "      <td>5.304</td>\n",
              "      <td>2.695</td>\n",
              "      <td>5.388</td>\n",
              "      <td>5.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       A      P       C     LK     WK  A_Coef   LKG\n",
              "0  11.49  13.22  0.8263  5.304  2.695   5.388  5.31"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXzvG17c6okD",
        "outputId": "5ef4fda0-0fb5-4b25-c70a-15b77d2e8fe7"
      },
      "source": [
        "type(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SomxFigv6YrZ",
        "outputId": "54b63476-a998-49d7-de56-60a4d719c322"
      },
      "source": [
        "predicted2 = model.predict(df2) \n",
        "predicted2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vc-hYDp46_k",
        "outputId": "edae338f-8b3c-43d1-97fe-b8a9ac6399e1"
      },
      "source": [
        "len(predicted2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2z_ICcLxub1"
      },
      "source": [
        "### Evaluating the KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_BNEwjIxub1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8v4_YZZ5aOk",
        "outputId": "780a6023-b401-47a7-9f17-65b1815481c6"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78     1\n",
              "65     0\n",
              "94     1\n",
              "22     0\n",
              "63     0\n",
              "46     0\n",
              "96     1\n",
              "11     0\n",
              "2      0\n",
              "155    2\n",
              "24     0\n",
              "101    1\n",
              "95     1\n",
              "74     1\n",
              "114    1\n",
              "160    2\n",
              "99     1\n",
              "82     1\n",
              "84     1\n",
              "108    1\n",
              "169    2\n",
              "162    2\n",
              "85     1\n",
              "188    2\n",
              "116    1\n",
              "150    2\n",
              "193    2\n",
              "133    1\n",
              "98     1\n",
              "168    2\n",
              "207    2\n",
              "204    2\n",
              "60     0\n",
              "126    1\n",
              "80     1\n",
              "170    2\n",
              "117    1\n",
              "57     0\n",
              "115    1\n",
              "9      0\n",
              "195    2\n",
              "106    1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_UvgA8b5dBk",
        "outputId": "aa5a8293-af11-4e8c-e0df-dea40e205124"
      },
      "source": [
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2,\n",
              "       1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sB18wK5xub2"
      },
      "source": [
        "dx=pd.DataFrame({'acturl': y_test, 'predict': predicted})\n",
        "#dx\n",
        "#dx[dx.acturl != dx.predict]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-YoFtMxxub2",
        "outputId": "65209e02-a9a2-4d3c-a6fc-970eca83e563"
      },
      "source": [
        "print(confusion_matrix(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9  0  1]\n",
            " [ 0 20  0]\n",
            " [ 0  0 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v10AB3WPxub3",
        "outputId": "709f1a7c-534a-480b-ee13-6bf52f14f9a4"
      },
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        10\n",
            "           1       1.00      1.00      1.00        20\n",
            "           2       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.98        42\n",
            "   macro avg       0.97      0.97      0.97        42\n",
            "weighted avg       0.98      0.98      0.98        42\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9OVgulwxub3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}